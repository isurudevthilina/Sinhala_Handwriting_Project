# create_unicode_mapping.py
# FIRST STEP: Create Unicode mapping for Sinhala characters
# Place this file in project-root/ and run it first

import json
import os
from pathlib import Path


def create_unicode_mapping():
    """Create Unicode mapping from class numbers to Sinhala characters"""

    # Your 454 Sinhala characters (in order from class 1 to 454)
    sinhala_classes = [
        "‡∂Ö", "‡∂Ü", "‡∂á", "‡∂à", "‡∂â", "‡∂ä", "‡∂ã", "‡∂ë", "‡∂í", "‡∂î", "‡∂ï",
        "‡∂ö", "‡∂ö‡∑è", "‡∂ö‡∑ê", "‡∂ö‡∑ë", "‡∂ö‡∑í", "‡∂ö‡∑ì", "‡∂ö‡∑î", "‡∂ö‡∑ñ", "‡∂ö‡∑ä", "‡∂ö‡∑ù", "‡∂ö‡∑ä‚Äç‡∂ª", "‡∂ö‡∑ä‚Äç‡∂ª‡∑í", "‡∂ö‡∑ä‚Äç‡∂ª‡∑ì",
        "‡∂ú", "‡∂ú‡∑è", "‡∂ú‡∑ê", "‡∂ú‡∑ë", "‡∂ú‡∑í", "‡∂ú‡∑ì", "‡∂ú‡∑î", "‡∂ú‡∑ñ", "‡∂ú‡∑ä", "‡∂ú‡∑ù", "‡∂ú‡∑ä‚Äç‡∂ª", "‡∂ú‡∑ä‚Äç‡∂ª‡∑í", "‡∂ú‡∑ä‚Äç‡∂ª‡∑ì",
        "‡∂†", "‡∂†‡∑è", "‡∂†‡∑ê", "‡∂†‡∑ë", "‡∂†‡∑í", "‡∂†‡∑ì", "‡∂†‡∑î", "‡∂†‡∑ñ", "‡∂†‡∑ä", "‡∂†‡∑ù", "‡∂†‡∑ä‚Äç‡∂ª", "‡∂†‡∑ä‚Äç‡∂ª‡∑ä", "‡∂†‡∑ä‚Äç‡∂ª‡∑ì",
        "‡∂¢", "‡∂¢‡∑è", "‡∂¢‡∑ê", "‡∂¢‡∑ë", "‡∂¢‡∑í", "‡∂¢‡∑ì", "‡∂¢‡∑î", "‡∂¢‡∑ñ", "‡∂¢‡∑ä", "‡∂¢‡∑ù", "‡∂¢‡∑ä‚Äç‡∂ª", "‡∂¢‡∑ä‚Äç‡∂ª‡∑í", "‡∂¢‡∑ä‚Äç‡∂ª‡∑ì",
        "‡∂ß", "‡∂ß‡∑è", "‡∂ß‡∑ê", "‡∂ß‡∑ë", "‡∂ß‡∑í", "‡∂ß‡∑ì", "‡∂ß‡∑î", "‡∂ß‡∑ñ", "‡∂ß‡∑ä", "‡∂ß‡∑ù", "‡∂ß‡∑ä‚Äç‡∂ª", "‡∂ß‡∑ä‚Äç‡∂ª‡∑ä", "‡∂ß‡∑ä‚Äç‡∂ª‡∑í",
        "‡∂©", "‡∂©‡∑è", "‡∂©‡∑ê", "‡∂©‡∑ë", "‡∂©‡∑í", "‡∂©‡∑ì", "‡∂©‡∑î", "‡∂©‡∑ñ", "‡∂©‡∑ä", "‡∂©‡∑ù", "‡∂©‡∑ä‚Äç‡∂ª", "‡∂©‡∑ä‚Äç‡∂ª‡∑ä", "‡∂©‡∑ä‚Äç‡∂ª‡∑í",
        "‡∂´", "‡∂´‡∑è", "‡∂´‡∑í",
        "‡∂≠", "‡∂≠‡∑è", "‡∂≠‡∑í", "‡∂≠‡∑ì", "‡∂≠‡∑î", "‡∂≠‡∑ñ", "‡∂≠‡∑ä", "‡∂≠‡∑ù", "‡∂≠‡∑ä‚Äç‡∂ª", "‡∂≠‡∑ä‚Äç‡∂ª‡∑è", "‡∂≠‡∑ä‚Äç‡∂ª‡∑í", "‡∂≠‡∑ä‚Äç‡∂ª‡∑ì",
        "‡∂Ø ", "‡∂Ø‡∑è", "‡∂Ø‡∑ê", "‡∂Ø‡∑ë", "‡∂Ø‡∑í", "‡∂Ø‡∑ì", "‡∂Ø‡∑î", "‡∂Ø‡∑ñ", "‡∂Ø‡∑ä", "‡∂Ø‡∑ù", "‡∂Ø‡∑ä‚Äç‡∂ª", "‡∂Ø‡∑ä‚Äç‡∂ª‡∑ù", "‡∂Ø‡∑ä‚Äç‡∂ª‡∑è", "‡∂Ø‡∑ä‚Äç‡∂ª‡∑í", "‡∂Ø‡∑ä‚Äç‡∂ª‡∑ì",
        "‡∂±", "‡∂±‡∑è", "‡∂±‡∑ê", "‡∂±‡∑ë", "‡∂±‡∑í", "‡∂±‡∑ì", "‡∂±‡∑î", "‡∂±‡∑ñ", "‡∂±‡∑ä", "‡∂±‡∑ù", "‡∂±‡∑ä‚Äç‡∂ª", "‡∂±‡∑ä‚Äç‡∂ª‡∑è", "‡∂±‡∑ä‚Äç‡∂ª‡∑í", "‡∂±‡∑ä‚Äç‡∂ª‡∑ì",
        "‡∂¥", "‡∂¥‡∑è", "‡∂¥‡∑ê", "‡∂¥‡∑ë", "‡∂¥‡∑í", "‡∂¥‡∑ì", "‡∂¥‡∑î", "‡∂¥‡∑ñ", "‡∂¥‡∑ä", "‡∂¥‡∑ä‚Äç‡∂ª‡∑ù", "‡∂¥‡∑ù", "‡∂¥‡∑ä‚Äç‡∂ª", "‡∂¥‡∑ä‚Äç‡∂ª‡∑è", "‡∂¥‡∑ä‚Äç‡∂ª‡∑í", "‡∂¥‡∑ä‚Äç‡∂ª‡∑ì",
        "‡∂∂", "‡∂∂‡∑è", "‡∂∂‡∑ê", "‡∂∂‡∑ë", "‡∂∂‡∑í", "‡∂∂‡∑ì", "‡∂∂‡∑î", "‡∂∂‡∑ñ", "‡∂∂‡∑ä", "‡∂∂‡∑ä‚Äç‡∂ª‡∑ù", "‡∂∂‡∑ä‚Äç‡∂ª", "‡∂∂‡∑ä‚Äç‡∂ª‡∑è", "‡∂∂‡∑ä‚Äç‡∂ª‡∑í", "‡∂∂‡∑ä‚Äç‡∂ª‡∑ì", "‡∂∂‡∑ä‚Äç‡∂ª‡∑ù",
        "‡∂∏", "‡∂∏‡∑è", "‡∂∏‡∑ê", "‡∂∏‡∑ë", "‡∂∏‡∑í", "‡∂∏‡∑ì", "‡∂∏‡∑î", "‡∂∏‡∑ñ", "‡∂∏‡∑ä", "‡∂∏‡∑ù", "‡∂∏‡∑ä‚Äç‡∂ª", "‡∂∏‡∑ä‚Äç‡∂ª‡∑è", "‡∂∏‡∑ä‚Äç‡∂ª‡∑í", "‡∂∏‡∑ä‚Äç‡∂ª‡∑ì", "‡∂∏‡∑ä‚Äç‡∂ª‡∑ù",
        "‡∂∫", "‡∂∫‡∑è", "‡∂∫‡∑ê", "‡∂∫‡∑ë", "‡∂∫‡∑í", "‡∂∫‡∑ì", "‡∂∫‡∑î", "‡∂∫‡∑ñ", "‡∑ù", "‡∂∫‡∑ä", "hda",
        "‡∂ª", "‡∂ª‡∑è", "‡∂ª‡∑ê", "‡∂ª‡∑ê", "‡∂ª‡∑î", "‡∂ª‡∑ñ", "‡∂ª‡∑í", "‡∂ª‡∑ì",
        "‡∂Ω", "‡∂Ω‡∑è", "‡∂Ω‡∑ê", "‡∂Ω‡∑ë", "‡∂Ω‡∑í", "‡∂Ω‡∑ì", "‡∂Ω‡∑î", "‡∂Ω‡∑ñ", "‡∂Ω‡∑ä", ",da",
        "‡∑Ä", "‡∑Ä‡∑è", "‡∑Ä‡∑ê", "‡∑Ä‡∑ë", "‡∑Ä‡∑í", "‡∑Ä‡∑ì", "‡∑Ä‡∑î", "‡∑Ä‡∑ñ", "‡∑Ä‡∑ä", "jda", "‡∑Ä‡∑ä‚Äç‡∂ª", "‡∑Ä‡∑ä‚Äç‡∂ª‡∑è", "‡∑Ä‡∑ä‚Äç‡∂ª‡∑ê", "‡∑Ä‡∑ä‚Äç‡∂ª‡∑ë", "j%da",
        "‡∑Å", "‡∑Å‡∑è", "‡∑Å‡∑ê", "‡∑Å‡∑ë", "‡∑Å‡∑í", "‡∑Å‡∑ì", "‡∑Å‡∑î", "‡∑Å‡∑ñ", "‡∑Å‡∑ä", "Yda", "‡∑Å‡∑ä‚Äç‡∂ª", "‡∑Å‡∑ä‚Äç‡∂ª‡∑è", "‡∑Å‡∑ä‚Äç‡∂ª‡∑ê", "‡∑Å‡∑ä‚Äç‡∂ª‡∑ë", "‡∑Å‡∑ä‚Äç‡∂ª‡∑í", "‡∑Å‡∑ä‚Äç‡∂ª‡∑ì",
        "Y%da",
        "‡∑Ç", "‡∑Ç‡∑è", "‡∑Ç‡∑ê", "‡∑Ç‡∑ë", "‡∑Ç‡∑í", "‡∑Ç‡∑ì", "‡∑Ç‡∑î", "‡∑Ç‡∑ñ", "‡∑Ç‡∑ä", "Ida",
        "‡∑É", "‡∑É‡∑è", "‡∑É‡∑ê", "‡∑É‡∑ë", "‡∑É‡∑í", "‡∑É‡∑ì", "‡∑É‡∑î", "‡∑É‡∑ñ", "ida", "‡∑É‡∑ä‚Äç‡∂ª", "‡∑É‡∑ä‚Äç‡∂ª‡∑è", "‡∑É‡∑ä‚Äç‡∂ª‡∑í", "‡∑É‡∑ä‚Äç‡∂ª‡∑ì", "‡∑É‡∑ä",
        "‡∑Ñ", "‡∑Ñ‡∑è", "‡∑Ñ‡∑ê", "‡∑Ñ‡∑ë", "‡∑Ñ‡∑í", "‡∑Ñ‡∑ì", "‡∑Ñ‡∑î", "‡∑Ñ‡∑ñ", "‡∑Ñ‡∑ä", "yda",
        "‡∑Ö", "‡∑Ö‡∑è", "‡∑Ö‡∑ê", "‡∑Ö‡∑ë", "‡∑Ö‡∑í", "‡∑Ö‡∑ì",
        "‡∑Ö‡∑ñ", "‡∑Ö‡∑ñ",
        "‡∑Ü", "‡∑Ü‡∑è", "‡∑Ü‡∑ê", "‡∑Ü‡∑ë", "‡∑Ü‡∑í", "‡∑Ü‡∑ì", "‡∑Ü‡∑ñ", "‡∑Ü‡∑ñ", "‡∑Ü‡∑ä‚Äç‡∂ª", "‡∑Ü‡∑ä‚Äç‡∂ª‡∑í", "‡∑Ü‡∑ä‚Äç‡∂ª‡∑ì", "‡∑Ü‡∑ä‚Äç‡∂ª‡∑ê", "‡∑Ü‡∑ä‚Äç‡∂ª‡∑ë", "‡∑Ü‡∑ä", "*da",
        "‡∂ö‡∑ä‚Äç‡∂ª‡∑è", "‡∂ö‡∑ä‚Äç‡∂ª‡∑ê", "‡∂ö‡∑ä‚Äç‡∂ª‡∑ë", "l%da", ".%da",
        "‡∂õ", "‡∂õ‡∑è", "‡∂õ‡∑í", "‡∂õ‡∑ì", "‡∂õ‡∑ä",
        "‡∂ù", "‡∂ù‡∑è", "‡∂ù‡∑ê", "‡∂ù‡∑ë", "‡∂ù‡∑í", "‡∂ù‡∑ì", "‡∂ù‡∑î", "‡∂ù‡∑ñ", ">da", "‡∂ù‡∑ä", "‡∂ù‡∑ä‚Äç‡∂ª", "‡∂ù‡∑ä‚Äç‡∂ª‡∑è", "‡∂ù‡∑ä‚Äç‡∂ª‡∑í", "‡∂ù‡∑ä‚Äç‡∂ª‡∑ì",
        "‡∂≥", "‡∂≥‡∑è", "‡∂≥‡∑ê", "‡∑ë", "‡∂≥‡∑ë", "‡∂≥‡∑í", "‡∂≥‡∑ì", "‡∂≥‡∑î", "‡∂≥‡∑ñ", "|da ", " ‡∂≥‡∑ä",
        "‡∂ü", "‡∂ü‡∑è", "‡∂ü‡∑ê", " ‡∂ü‡∑ë", " ‡∂ü‡∑í", "‡∂ü‡∑ì", " ‡∂ü‡∑î", " ‡∂ü‡∑ñ", "√ïda", "‡∂ü‡∑ä",
        "‡∂¨", "‡∑ê", "‡∂¨‡∑è", " ‡∂¨‡∑ê", "‡∂¨‡∑ë", " ‡∂¨‡∑í", "‡∂¨‡∑ì", " ‡∂¨‡∑î", "‡∂¨‡∑ñ", "‡∂¨da ", " ‡∂¨‡∑ä",
        "‡∂π", "‡∂π‡∑è", " ‡∂π‡∑ê", " ‡∂π‡∑ë", " ‡∂π‡∑í", "‡∂π‡∑ì", " ‡∂π‡∑î", "‡∂π‡∑ñ", "Uda", "‡∂π‡∑ä",
        "‡∂∑", "‡∂∑‡∑è", "‡∂∑‡∑ê", "‡∂∑‡∑ë", "‡∂∑‡∑í", "‡∂∑‡∑ì", "‡∂∑‡∑î", "‡∂∑‡∑ñ", "Nda", "‡∂∑‡∑ä",
        "‡∂∞", "‡∂∞‡∑è", "‡∂∞‡∑ê", "‡∂∞‡∑ë", ",‡∂∞‡∑í", ",‡∂∞‡∑ì", ",‡∂∞‡∑î", ",‡∂∞‡∑ñ", "‡∂∞‡∑ù", "‡∂∞‡∑ä",
        "‡∂®", "‡∂®‡∑è", "‡∂®‡∑ê", "‡∂®‡∑í", "‡∂®‡∑ì", "‡∂®‡∑î", "‡∂®‡∑ñ", "‡∂®‡∑ä", "‡∂™", "‡∂™‡∑è", "‡∂™‡∑í", "Vda",
        "‡∂µ", "‡∂µ‡∑è", "‡∂µ‡∑î", "‡∂µ‡∑í", "Mda", "‡∂µ‡∑ä ", "‡∂Æ", "‡∂Æ‡∑è", "‡∂Æ‡∑ê", "‡∂Æ‡∑ä", "‡∑è", "‡∑ü", "‡∂´‡∑ê", "‡∂´‡∑ë", "‡∑ò", "‡∂´‡∑ì", "‡∂´‡∑î", "‡∂´‡∑ñ",
        "Kda", "‡∂´‡∑ä", "‡∂•", "‡∂•‡∑è", "{da", "‡∂§", "‡∂§‡∑è", "‡∂§‡∑î", "[da", "‡∂§‡∑ä", "‡∂£", "‡∂£‡∑è", "‡∂£‡∑î", "COda",
        "‡∂£‡∑ä", "‡∂¶", "‡∂¶‡∑è", "‡∂¶‡∑ê", "‡∂¶‡∑ë", "‡∂¶‡∑í", "‡∂¶‡∑î", "‡∂¶‡∑ñ", "‡∂¶‡∑ù",
        "‡∂¶‡∑ä", "‡∂°", "‡∂°‡∑è", "‡∂°‡∑ê", "‡∂°‡∑ë", "‡∂°‡∑í", "‡∂°‡∑ö", "‡∂≠‡∑ê", "‡∂≠‡∑ë", "‡∂≠‡∑ä‚Äç‡∂ª‡∑ê", "‡∂≠‡∑ä‚Äç‡∂ª‡∑ë", ";%da",
        "‡∑Ö‡∑î", "‡∑≤", "HQ", "ff", "f", "H", "Hq"
    ]

    def categorize_character(char):
        """Categorize each Sinhala character"""
        char = char.strip()

        # Independent vowels
        if char in ["‡∂Ö", "‡∂Ü", "‡∂á", "‡∂à", "‡∂â", "‡∂ä", "‡∂ã", "‡∂ë", "‡∂í", "‡∂î", "‡∂ï"]:
            return "independent_vowel"

        # Base consonants (single characters)
        elif char in ["‡∂ö", "‡∂ú", "‡∂†", "‡∂¢", "‡∂ß", "‡∂©", "‡∂´", "‡∂≠", "‡∂Ø", "‡∂±", "‡∂¥", "‡∂∂", "‡∂∏", "‡∂∫", "‡∂ª", "‡∂Ω", "‡∑Ä", "‡∑Å", "‡∑Ç",
                      "‡∑É", "‡∑Ñ", "‡∑Ö", "‡∑Ü", "‡∂õ", "‡∂ù", "‡∂≥", "‡∂ü", "‡∂¨", "‡∂π", "‡∂∑", "‡∂∞", "‡∂®", "‡∂™", "‡∂µ", "‡∂Æ", "‡∂•", "‡∂§", "‡∂£",
                      "‡∂¶", "‡∂°"]:
            return "base_consonant"

        # Consonant + vowel combinations
        elif any(vowel in char for vowel in ["‡∑è", "‡∑ê", "‡∑ë", "‡∑í", "‡∑ì", "‡∑î", "‡∑ñ", "‡∑ù", "‡∑ö", "‡∑ú"]):
            return "consonant_vowel_combination"

        # Consonant + ‡∂ª combinations
        elif "‡∑ä‚Äç‡∂ª" in char:
            return "consonant_r_combination"

        # Consonant clusters (with halanta ‡∑ä)
        elif "‡∑ä" in char and len(char) > 1:
            return "consonant_cluster"

        # Encoded/special characters
        elif any(marker in char for marker in ["da", "HQ", "ff", "f", "H", "Hq"]):
            return "encoded_character"

        # Other vowel signs
        elif char in ["‡∑è", "‡∑ê", "‡∑ë", "‡∑í", "‡∑ì", "‡∑î", "‡∑ñ", "‡∑ù", "‡∑ö", "‡∑ú", "‡∑ò", "‡∑ü", "‡∑≤"]:
            return "vowel_sign"

        else:
            return "other"

    # Create the mapping structure
    unicode_mapping = {
        "dataset_info": {
            "total_classes": len(sinhala_classes),
            "dataset_name": "Sinhala Letter 454",
            "source": "https://www.kaggle.com/datasets/sathiralamal/sinhala-letter-454",
            "description": "Sinhala handwritten character recognition dataset",
            "created_by": "Group 2025-Y2-S1-MLB-B8G1-04",
            "team_members": [
                "IT24102111 - Thiqa Zibrij A.G",
                "IT24102160 - Gangamini A.H.A.",
                "IT24102051 - Madhushan P.S.A.D.Y",
                "IT24102031 - Disanayaka K.G.G.S",
                "IT24102090 - Bandara D M R M",
                "IT24102032 - Thilina N.A.D.I.D"
            ]
        },
        "class_to_unicode": {},
        "unicode_to_class": {},
        "category_distribution": {}
    }

    # Build the mappings
    category_counts = {}

    for i, char in enumerate(sinhala_classes, 1):  # Start from class 1
        class_id = str(i)
        char_clean = char.strip()
        category = categorize_character(char_clean)

        # Count categories
        category_counts[category] = category_counts.get(category, 0) + 1

        # Create character info
        char_info = {
            "unicode": char_clean,
            "category": category,
            "class_id": i,
            "index": i - 1  # 0-based index for programming
        }

        # Add to mappings
        unicode_mapping["class_to_unicode"][class_id] = char_info
        unicode_mapping["unicode_to_class"][char_clean] = i

    # Add category distribution
    unicode_mapping["category_distribution"] = category_counts

    return unicode_mapping


def save_mapping():
    """Save the Unicode mapping to JSON file"""

    # Create directory structure
    base_path = Path(".")
    mapping_dir = base_path / "data" / "mappings"
    mapping_dir.mkdir(parents=True, exist_ok=True)

    # Generate mapping
    mapping = create_unicode_mapping()

    # Save to file
    output_file = mapping_dir / "unicode_mapping.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(mapping, f, indent=2, ensure_ascii=False)

    print("=" * 60)
    print("UNICODE MAPPING CREATED SUCCESSFULLY!")
    print("=" * 60)
    print(f"üìÑ File saved: {output_file}")
    print(f"üìä Total classes: {mapping['dataset_info']['total_classes']}")
    print("\nüìà Category Distribution:")
    for category, count in mapping['category_distribution'].items():
        print(f"   {category}: {count}")

    print("\n‚úÖ Examples:")
    for i in [1, 12, 25, 100, 200, 454]:
        if str(i) in mapping['class_to_unicode']:
            char_info = mapping['class_to_unicode'][str(i)]
            print(f"   Class {i}: '{char_info['unicode']}' ({char_info['category']})")

    print(f"\nüéØ Ready for preprocessing! Each member can now use this mapping.")
    print("=" * 60)

    return output_file


if __name__ == "__main__":
    save_mapping()